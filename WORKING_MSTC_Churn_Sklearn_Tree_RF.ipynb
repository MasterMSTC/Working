{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WORKING_MSTC_Churn_Sklearn_Tree_RF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [tensorflow]",
      "language": "python",
      "name": "Python [tensorflow]"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "wgcJWurtFMPk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Churn prediction <font color=orange>(Orange Telecom dataset)</font>\n",
        "## using Python ML <font color=blue>scikit-learn</font> http://scikit-learn.org/stable/\n",
        "\n",
        "![Image of Sklearn](http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)\n",
        "![Image of Sklearn](http://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001_carousel.png)\n",
        "\n",
        "\n",
        "### see http://blog.yhat.com/posts/predicting-customer-churn-with-sklearn.html"
      ]
    },
    {
      "metadata": {
        "id": "cky6YKezGPSh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Reading *churn_bigml* data from a Shared Google Drive .tar file"
      ]
    },
    {
      "metadata": {
        "id": "0VhD24xbGPdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install googledrivedownloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8i886DuOGTRm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1zmriEGA3z4WAOmscdEfgzcliAUsNaVoj',\n",
        "                                    dest_path='./churn-bigml.zip',\n",
        "                                    unzip=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mI2voHcxGfjo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! unzip -o churn-bigml.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZ4jv0z5adAz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## <font color=#FF103>TO DO: read churn-bigml-80.csv into a Pandas DataFrame</font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fK5_L-byF5Af",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "CV_data = ???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CiIFfwsGFMP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CV_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2u7R11pNbTpV"
      },
      "cell_type": "markdown",
      "source": [
        "## <font color=#FF103>TO DO: how many features (columns) do we have? </font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WmGWVPufdypF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "col_names = ???\n",
        "\n",
        "print(\"There are : \" , len(col_names) ,' columns')\n",
        "print('\\nColumn names: \\n {}'.format(col_names))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7keWYeb8bI1p"
      },
      "cell_type": "markdown",
      "source": [
        "## <font color=#FF103>TO DO: how many users and how many quit and don't quit</font>"
      ]
    },
    {
      "metadata": {
        "id": "2zDusTVeeHg5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wd8mcaIp2Enh"
      },
      "cell_type": "markdown",
      "source": [
        "## <font color=#FF103>TO DO: make a <font color=green>bar plot</font> on the average 'Customer service calls' for each state</font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d1mJqQxN2N-f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 'Customer service calls'\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bbIe_OBmf32-"
      },
      "cell_type": "markdown",
      "source": [
        "## <font color=#FF103>TO DO: make a <font color=green>bar plot</font> on the percentage of users that quit for each state</font>"
      ]
    },
    {
      "metadata": {
        "id": "RRbk7IAr01BX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Pvog_Y_FMQf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# <font color=qq6677>Now we prepare the data for testing several ML algorihms</font>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "id": "aa61C3wEpVXx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- ## <font color=FF103>TO DO: First Extract the Churn into a \"1\" \"0\" numpy vector = *y*"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7b-2YfcZqFRc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = ???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-tEGXIafqR7t"
      },
      "cell_type": "markdown",
      "source": [
        "- ## <font color=FF103>TO DO: Create a new Data Frame *churn_feat_space* by removing the columns in : *to_drop* list</font>\n",
        "  \n",
        "  "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rbMDDhLZrddN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "to_drop = ['State','Area code',\n",
        "           'Total day charge','Total eve charge','Total night charge',\n",
        "           'Total intl charge','Churn']\n",
        "\n",
        "churn_feat_space = ???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGBXIc6NFMRt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "churn_feat_space.head(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9GsRn1ywtpCA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- ## <font color=FF103>TO DO: Finally convert columns with Yes / No values ('International plan', 'Voice mail plan')to \"1\" \"0\" values in *churn_feat_space*</font>\n"
      ]
    },
    {
      "metadata": {
        "id": "Af9CiHpEsce4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yes_no_cols = ['International plan', 'Voice mail plan']\n",
        "\n",
        "???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HdNfw9yYFMR-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "churn_feat_space.head(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MuhtDXpdwCdn"
      },
      "cell_type": "markdown",
      "source": [
        "- ## <font color=FF103>TO DO: Finally convert *churn_feat_space* into a numpy array X_tmp</font>\n"
      ]
    },
    {
      "metadata": {
        "id": "AmAyUUsCvZ1f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_tmp=???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WrXElEniFMSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Number of Features:',X_tmp.shape[1])\n",
        "print('Number of training examples:',X_tmp.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Afl8nY9vwyXD"
      },
      "cell_type": "markdown",
      "source": [
        "- ## <font color=FF103>TO DO: Chech if features are \"normalized\" </font>\n"
      ]
    },
    {
      "metadata": {
        "id": "WqpAUucAxChL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Features Means:',???)\n",
        "print('Features Stds:',???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "J6ArmxbxxPNl"
      },
      "cell_type": "markdown",
      "source": [
        "- ## <font color=FF103>TO DO: use <font color=brown>Sklearn</font> to Normalize X_tmp into X </font>\n",
        "\n",
        "- ### sklearn.preprocessing : [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CbGkpGkJzOdy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Standarization of features\n",
        "from ??? import ???\n",
        "scaler = ???\n",
        "X = ???\n",
        "\n",
        "print('Features Means:',np.mean(X,axis=0))\n",
        "print('Features Stds:',np.std(X,axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0UlEGgmHzCcB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# See Pipelines...."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ee6LYYxlzBdF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# Fit to data using pipelined scaling, and PCA.\n",
        "scaler_pca = make_pipeline(StandardScaler(), PCA(n_components=5))\n",
        "X_PCA = scaler_pca.fit_transform(X_tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-VIAsjzp0sEN"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color=FF103>TO DO: apply the same process to TEST data churn-bigml-20.csv </font>\n",
        "\n",
        "- ## Generate X_test and y_test \n"
      ]
    },
    {
      "metadata": {
        "id": "w8LT_n7i0-Bd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "???\n",
        "\n",
        "print('Test: Features Means:',np.mean(X_test,axis=0))\n",
        "print('Test: Features Stds:',np.std(X_test,axis=0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TBYskIFcFMTW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "\n",
        "# <font color=green>Now: Fitting Models and Assessment</font>\n",
        "http://dataaspirant.com/2017/04/15/implement-logistic-regression-model-python-binary-classification/"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fAWs1QqivNuy"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color=FF103>TO DO: Fit a <font color=green>LogisticRegression</font> on X (churn-bigml-80.cv) and TEST data on churn-bigml-20.csv </font>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "V0LySYJ87DjC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from ??? import ???\n",
        "\n",
        "???\n",
        "\n",
        "y_pred_train = ???.predict(X)\n",
        "y_pred_test = ???.predict(X_test)\n",
        "\n",
        "ACC_train= np.mean(y == y_pred_train)\n",
        "ACC_test= np.mean(y_test == y_pred_test)\n",
        "\n",
        "print(\"Accuracy: Classification Error on TRAIN Data using LR %f \" % ACC_train)\n",
        "print(\"Accuracy: Classification Error on TEST  Data using LR %f \" % ACC_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "og3AXpBcyBB-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color=FF103>TO DO: Now fit a <font color=green>SVM</font> on X (churn-bigml-80.cv) and TEST data on churn-bigml-20.csv </font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AFImsk-U759b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from ??? import ???\n",
        "\n",
        "???\n",
        "\n",
        "???\n",
        "\n",
        "ACC_SVM_train= \n",
        "ACC_SVM_test= \n",
        "\n",
        "print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n",
        "print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QIiHycIYyLrJ"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color=FF103>TO DO: ... what are the LR and SVM hyperparameters? are the \"best\"? </font>"
      ]
    },
    {
      "metadata": {
        "id": "WzjOZEl3ynjn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4SwBtjPoyeRG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fcy-LoyGzMnh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# <font color=FF103>TO DO: ... search for best SVM hyperparameters?  </font>\n",
        "## See: [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\n",
        "---\n",
        "\n",
        "## Try:\n",
        "\n",
        "- ### Kernel rbf\n",
        "- ### gamma values  1e-2, 1e-3\n",
        "- ### C values , 1, 10, 100, 1000"
      ]
    },
    {
      "metadata": {
        "id": "PRIfL-189c62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tuned_parameters = [{'kernel': ???\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "                     \n",
        "clf=???\n",
        "                     \n",
        "                     \n",
        "                     \n",
        "                     \n",
        "clf.fit(X, y)\n",
        "\n",
        "\n",
        "print(\"Best parameters set found on development set:\")\n",
        "print(\"\\n\")\n",
        "print(clf.best_params_)\n",
        "\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "                     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rmOHLvbEzmYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Detailed classification report:\")\n",
        "print(\"\\n\")\n",
        "print(\"The model is trained on the full development set.\")\n",
        "print(\"The scores are computed on the full evaluation set.\")\n",
        "print(\"\\n\")\n",
        "y_true, y_pred = y_test, clf.predict(X_test)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uBpyB2ZmBOEw"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color=FF103>TO DO: ... now train SVM with the best set of hyperparameters and do the test on X_test </font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8CsxlWxuBn_A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM_model = SVC(???)\n",
        "\n",
        "SVM_model.fit(X,y)\n",
        "\n",
        "y_pred_train = SVM_model.predict(X)\n",
        "y_pred_test = SVM_model.predict(X_test)\n",
        "\n",
        "ACC_SVM_train= np.mean(y == y_pred_train)\n",
        "ACC_SVM_test= np.mean(y_test == y_pred_test)\n",
        "\n",
        "print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n",
        "print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8eJNOt-N-we",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM_model = SVC(probability=True, kernel = 'rbf', C = 10, gamma= 0.01)\n",
        "\n",
        "SVM_model.fit(X,y)\n",
        "\n",
        "y_pred_train = SVM_model.predict(X)\n",
        "y_pred_test = SVM_model.predict(X_test)\n",
        "\n",
        "ACC_SVM_train= np.mean(y == y_pred_train)\n",
        "ACC_SVM_test= np.mean(y_test == y_pred_test)\n",
        "\n",
        "print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n",
        "print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TCA3ChGR0I-m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font color=red>See: </font>[Nested versus non-nested cross-validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "id": "5PtgLLKpFMUL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color=FF103>TO DO: remember it is very important to go beyond Accuracy   </font>\n",
        "- ## Check what accuraccy we will have if you predict always \"True\" "
      ]
    },
    {
      "metadata": {
        "id": "EClRay7_4ot8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_false_train = np.zeros(len(y))\n",
        "y_false_test = np.zeros(len(y_test)) \n",
        "\n",
        "ACC_false_train= np.mean(y == y_false_train)\n",
        "ACC_false_test= np.mean(y_test == y_false_test)\n",
        "\n",
        "print(\"Accuracy: Classification Error on TRAIN Data using False %f \" % ACC_false_train)\n",
        "print(\"Accuracy: Classification Error on TEST  Data using False %f \" % ACC_false_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n",
        "print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Accuracy: Classification Error on TRAIN Data using LR %f \" % ACC_train)\n",
        "print(\"Accuracy: Classification Error on TEST  Data using LR %f \" % ACC_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8zx8rrHh8eyl"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font color=FF103>TO DO: ... beyond Accuracy   </font>\n",
        "- ## Explore the confusion matrix. on y_test  & y_pred_test with SVM  "
      ]
    },
    {
      "metadata": {
        "id": "n8rVrxLsFMUO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test,y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v2pXkeye8_Th",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- ## ... as with Deep Learning we can use the <font color=darkorange>PANDAS</font> confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "AGcELZArFMUT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install pandas_ml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXXdLHMuFMUX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pandas_ml import ConfusionMatrix\n",
        "\n",
        "cm = ConfusionMatrix(y_test,y_pred_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCnwoYcfFMUf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm.print_stats()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vf9SNXTw9x3F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDqouZ51FMUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm.plot(backend='seaborn',normalized=True)\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WrIGdni4FMUm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font color=FF103>TO DO: ... beyond Accuracy   </font>\n",
        "- ## Posterior probabilities are needed to analyze DET (or ROC) curves"
      ]
    },
    {
      "metadata": {
        "id": "GvgNpYtOFMUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First get posteriors...\n",
        "probs = SVM_model.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbpzkHHDFMUr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "preds = probs[:,1]\n",
        "\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "print('AUC : %f' % roc_auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbglTaiRFMUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WDUaXIVrJFc0"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font color=FF103>TO DO: try improving the prediction of churn True cases  </font>\n",
        "\n",
        "## See SVC docummentation: [sklearn SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
        "\n",
        "**class_weight : {dict, ‘balanced’}, optional**\n",
        "\n",
        "     Set the parameter C of class i to class_weight[i]*C for SVC.\n",
        "        example: class_weight={1: 10}\n",
        "    \n",
        "    If not given, all classes are supposed to have weight one.\n",
        "    \n",
        "    The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n",
        "\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lrjIAkYMDQCM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM_model = SVC(probability=True, kernel = 'rbf', C = 10, gamma= 0.01, class_weight=???)\n",
        "\n",
        "\n",
        "SVM_model.fit(X,y)\n",
        "\n",
        "y_pred_train = SVM_model.predict(X)\n",
        "y_pred_test = SVM_model.predict(X_test)\n",
        "\n",
        "ACC_SVM_train= np.mean(y == y_pred_train)\n",
        "ACC_SVM_test= np.mean(y_test == y_pred_test)\n",
        "\n",
        "print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n",
        "print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "elOE5GBhO3jj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm = ConfusionMatrix(y_test,y_pred_test)\n",
        "cm.plot(backend='seaborn',normalized=True)\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U1hMvzosFMU3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compare with QDA"
      ]
    },
    {
      "metadata": {
        "id": "nhUbt_6uFMU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CrDTfHrxDk20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- ## In this case you can use  *priors*=( ?? ,  ??)\n",
        "\n",
        "### Sklearn documentation: [QuadraticDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)"
      ]
    },
    {
      "metadata": {
        "id": "XFceBX76FMU-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qda_model = QuadraticDiscriminantAnalysis(priors=(0.45,0.55))\n",
        "qda_model.fit(X,y)\n",
        "\n",
        "y_pred_qda = qda_model.predict(X_test)\n",
        "probs_qda = qda_model.predict_proba(X_test)\n",
        "\n",
        "preds_qda = probs_qda[:,1]\n",
        "fpr_qda, tpr_qda, threshold_qda = metrics.roc_curve(y_test, preds_qda)\n",
        "roc_auc_qda = metrics.auc(fpr_qda, tpr_qda)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC LR = %0.2f' % roc_auc)\n",
        "plt.plot(fpr_qda, tpr_qda, 'g', label = 'AUC QDA = %0.2f' % roc_auc_qda)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGLjox_gFMVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm_qda = ConfusionMatrix(y_test, y_pred_qda)\n",
        "cm_qda.plot(backend='seaborn',normalized=True)\n",
        "print(cm_qda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-H6XLi8FMVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm_qda.print_stats()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8z5p6QUfAb94"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# <font color=FF103>TO DO: In case you need \"interpretability\"  </font>\n",
        "\n",
        "- ### USE:  max_depth=3"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "colab_type": "text",
        "id": "oHp5bqUuAb-B"
      },
      "cell_type": "markdown",
      "source": [
        "## <font color='green'>Using Classification Tree</font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AefMLD6OAb-I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from ??? import ???\n",
        "\n",
        "tree_model = ???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-4hrdyfaAb-j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(tree_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wsKt1oboAb-v"
      },
      "cell_type": "markdown",
      "source": [
        "- ## To visualize the tree"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "srWOx0utAb-x",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! apt-get update\n",
        "! apt-get autoremove graphviz\n",
        "! apt-get install graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l4VuYlw0Ab_A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MnnSGZOqAb_O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install pydotplus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_pHSdmKFG0V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## NOTE: we have used : labels=churn_feat_space.columns.tolist()\n",
        "\n",
        "        To see the label names in the tree"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qnkLrvPwAb_f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.externals.six import StringIO\n",
        "from graphviz import Source\n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "from sklearn import tree\n",
        "from IPython.display import SVG\n",
        "\n",
        "dot_data = StringIO()\n",
        "\n",
        "labels=churn_feat_space.columns.tolist()\n",
        "\n",
        "\n",
        "graph = Source(tree.export_graphviz(tree_model, out_file=None\n",
        "   , feature_names=labels\n",
        "   , class_names=['Churn', 'No_Churn'] \n",
        "   , filled = True))\n",
        "\n",
        "display(SVG(graph.pipe(format='svg')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ihVT41ypAb_4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# NOTE : Scaling\n",
        "\n",
        "churn_feat_space.hist('Total day minutes')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUmJpySoFUP9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- ## Adding the ROC for the tree"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CLOLPz5vAcAG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_tree = tree_model.predict(X)\n",
        "probs_tree = tree_model.predict_proba(X)\n",
        "\n",
        "preds_tree = probs_tree[:,1]\n",
        "fpr_tree, tpr_tree, threshold_tree = metrics.roc_curve(y, preds_tree)\n",
        "roc_auc_tree = metrics.auc(fpr_tree, tpr_tree)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC LR = %0.2f' % roc_auc)\n",
        "plt.plot(fpr_qda, tpr_qda, 'g', label = 'AUC QDA = %0.2f' % roc_auc_qda)\n",
        "plt.plot(fpr_tree, tpr_tree, 'm', label = 'AUC TREE = %0.2f' % roc_auc_tree)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2hkM2pVKAcAR"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font color=FF103>TO DO: ... try Gradient Boosting  </font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KfRxkYoeAcAV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# boosting: many many weak classifiers (max_depth=1) refine themselves sequentially\n",
        "# tree is the default the base classifier\n",
        "estimator = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=1, random_state=0)\n",
        "estimator.fit(X, y)\n",
        "y_pred = estimator.predict(X)\n",
        "print(classification_report(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "h-e8PmjSAcAg"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font color=FF103>TO DO: ... try Random Forest  </font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1Ff03JN4AcAi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2h1d09o-AcAn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RF_model = RandomForestClassifier(max_depth=10,min_samples_split=20).fit(X, y)\n",
        "RF_model.fit(X, y)\n",
        "y_pred_RF = RF_model.predict(X)\n",
        "print(classification_report(y, y_pred_RF))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XqruE4tCAcAy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RF_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67TDgHtdFlrn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color=FF103>TO DO: ... review how you can with Random Forest study <font color=green>Feature importances  </font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HyUGfI1hAcBP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels=churn_feat_space.columns.tolist()\n",
        "\n",
        "\n",
        "importances = RF_model.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in RF_model.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X.shape[1]):\n",
        "    print(\"%d. feature %s (%f)\" % (f + 1, labels[indices[f]], importances[indices[f]]))\n",
        "\n",
        "# Plot the feature importances of the forest\n",
        "plt.figure(figsize=(14,8))\n",
        "plt.title(\"Feature importances\", fontsize=20)\n",
        "plt.bar(range(X.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), [labels[k] for k in indices],rotation='vertical')\n",
        "ax = plt.gca()\n",
        "ax.tick_params(axis = 'both', which = 'major', labelsize = 16)\n",
        "\n",
        "plt.xlim([-1, X.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ep6oODTIAcBX"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font color=FF103>TO DO: ... try GridSearch for Random Forest  </font>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rlkFK61_AcBa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XMcjL9k6AcBk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from time import time\n",
        "\n",
        "RF_grid = RandomForestClassifier(n_estimators=20)\n",
        "\n",
        "# use a full grid over all parameters\n",
        "param_grid = {\"max_depth\": [3, None],\n",
        "              \"max_features\": [1, 3, 10],\n",
        "              \"min_samples_split\": [2, 3, 10],\n",
        "              \"bootstrap\": [True, False],\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(RF_grid, param_grid=param_grid, cv=5)\n",
        "start = time()\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
        "report(grid_search.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "25B7Z1tUFMVa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <font color=brown>You can also use: Model selection with Cross validation</font> using scikit-learn libraries.\n",
        "https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html#k-fold\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BNdcgWrdFMVb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('QDA', QuadraticDiscriminantAnalysis()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uo3Xtt6gFMVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xros-2E-FMVm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}