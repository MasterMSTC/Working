{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DAY2_MSTC_Churn_Sklearn_Tree_RF.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [tensorflow]","language":"python","name":"Python [tensorflow]"}},"cells":[{"metadata":{"id":"wgcJWurtFMPk","colab_type":"text"},"cell_type":"markdown","source":["#  Churn prediction <font color=orange>(Orange Telecom dataset)</font>\n","## using Python ML <font color=blue>scikit-learn</font> http://scikit-learn.org/stable/\n","\n","![Image of Sklearn](http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)\n","![Image of Sklearn](http://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001_carousel.png)\n","\n","\n","### see http://blog.yhat.com/posts/predicting-customer-churn-with-sklearn.html"]},{"metadata":{"id":"cky6YKezGPSh","colab_type":"text"},"cell_type":"markdown","source":["---\n","\n","# Reading *churn_bigml* data from a Shared Google Drive .tar file"]},{"metadata":{"id":"0VhD24xbGPdc","colab_type":"code","colab":{}},"cell_type":"code","source":["! pip install googledrivedownloader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8i886DuOGTRm","colab_type":"code","colab":{}},"cell_type":"code","source":["from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","gdd.download_file_from_google_drive(file_id='1zmriEGA3z4WAOmscdEfgzcliAUsNaVoj',\n","                                    dest_path='./churn-bigml.zip',\n","                                    unzip=False)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mI2voHcxGfjo","colab_type":"code","colab":{}},"cell_type":"code","source":["! unzip -o churn-bigml.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_Pvog_Y_FMQf","colab_type":"text"},"cell_type":"markdown","source":["---\n","\n","# <font color=qq6677>Prepare:</font>\n","- ## Training -Cross-Validation- data:  churn-bigml-80.csv\n","- ## Test data:  churn-bigml-20.csv\n","  \n","# <font color=qq6677>  for comparing several ML algorihms</font>\n","\n","---\n"]},{"metadata":{"id":"hZ4jv0z5adAz","colab_type":"text"},"cell_type":"markdown","source":["## <font color=#FF103>Prepare Train (CV) data using Pandas DataFrame</font>"]},{"metadata":{"colab_type":"code","id":"fK5_L-byF5Af","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","## SEE FEATURE ENGINEERING at Moodle PRDL\n","# WE are not going to use some features\n","\n","to_drop = ['State','Area code',\n","           'Total day charge','Total eve charge','Total night charge',\n","           'Total intl charge','Churn']\n","\n","yes_no_cols = ['International plan', 'Voice mail plan']\n","\n","\n","\n","CV_data = CV_data = pd.read_csv(\"churn-bigml-80.csv\")\n","\n","# The \"y\" outcome\n","y = np.array(CV_data['Churn']).astype(int)\n","\n","# \"X\" : the Predictors / feature space\n","\n","churn_feat_space = CV_data.drop(to_drop,axis=1)\n","\n","churn_feat_space[yes_no_cols]= (churn_feat_space[yes_no_cols]=='Yes').astype(int)\n","\n","X_tmp=np.array(churn_feat_space)\n","\n","# Standarization of features\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","scaler.fit(X_tmp)\n","\n","X=scaler.transform(X_tmp)\n","\n","# You could also:\n","# X = scaler.fit.transform(X_tmp)\n","# or use only X and NOT X_tmp (but be careful if you execute this cell twice!)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0UlEGgmHzCcB","colab_type":"text"},"cell_type":"markdown","source":["# See Pipelines...."]},{"metadata":{"colab_type":"code","id":"ee6LYYxlzBdF","colab":{}},"cell_type":"code","source":["from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","\n","# Fit to data using pipelined scaling, and PCA.\n","scaler_pca = make_pipeline(StandardScaler(), PCA(n_components=5))\n","X_PCA = scaler_pca.fit_transform(X_tmp)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"u6u97Cm2VjKC"},"cell_type":"markdown","source":["---\n","## <font color=#FF103>Prepare Test  ( churn-bigml-20.csv) in a same way than Train (CV)</font>\n","\n","- ### We will generate X_test and y_test \n","\n"]},{"metadata":{"id":"0lMwANIAWArh","colab_type":"code","colab":{}},"cell_type":"code","source":["Test_data = pd.read_csv(\"churn-bigml-20.csv\")\n","\n","y_test = np.array(Test_data['Churn']).astype(int)\n","\n","test_churn_feat_space = Test_data.drop(to_drop,axis=1)\n","\n","test_churn_feat_space[yes_no_cols]= \\\n","        (test_churn_feat_space[yes_no_cols]=='Yes').astype(int)\n","\n","X_test_tmp = np.array(test_churn_feat_space)\n","\n","X_test = scaler.transform(X_test_tmp)\n","\n","print('Test: Features Means:',np.mean(X_test,axis=0))\n","print('Test: Features Stds:',np.std(X_test,axis=0))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TBYskIFcFMTW","colab_type":"text"},"cell_type":"markdown","source":["---\n","---\n","\n","\n","# <font color=green>Now: Fitting Models and Assessment</font>\n","http://dataaspirant.com/2017/04/15/implement-logistic-regression-model-python-binary-classification/"]},{"metadata":{"colab_type":"text","id":"fAWs1QqivNuy"},"cell_type":"markdown","source":["# <font color=FF103>TO DO: Fit a <font color=green>LogisticRegression</font> on X (churn-bigml-80.cv) and TEST data on churn-bigml-20.csv </font>\n","\n"]},{"metadata":{"colab_type":"code","id":"V0LySYJ87DjC","colab":{}},"cell_type":"code","source":["from ??? import ???\n","\n","???    .fit\n","\n","y_pred_train = ???.predict(X)\n","y_pred_test = ???.predict(X_test)\n","\n","ACC_train= np.mean(y == y_pred_train)\n","ACC_test= np.mean(y_test == y_pred_test)\n","\n","print(\"Accuracy: Classification Error on TRAIN Data using LR %f \" % ACC_train)\n","print(\"Accuracy: Classification Error on TEST  Data using LR %f \" % ACC_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"og3AXpBcyBB-","colab_type":"text"},"cell_type":"markdown","source":["# <font color=FF103>TO DO: Now fit a <font color=green>SVM</font> on X (churn-bigml-80.cv) and TEST data on churn-bigml-20.csv </font>"]},{"metadata":{"colab_type":"code","id":"AFImsk-U759b","colab":{}},"cell_type":"code","source":["from ??? import ???\n","\n","???\n","\n","???\n","\n","ACC_SVM_train= \n","ACC_SVM_test= \n","\n","print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n","print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"QIiHycIYyLrJ"},"cell_type":"markdown","source":["# <font color=FF103>TO DO: ... what are the LR and SVM hyperparameters? are the \"best\"? </font>"]},{"metadata":{"id":"WzjOZEl3ynjn","colab_type":"code","colab":{}},"cell_type":"code","source":["???"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4SwBtjPoyeRG","colab_type":"code","colab":{}},"cell_type":"code","source":["???"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Fcy-LoyGzMnh","colab_type":"text"},"cell_type":"markdown","source":["---\n","---\n","\n","# <font color=FF103>TO DO: ... search for best SVM hyperparameters?  </font>\n","## See: [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\n","---\n","\n","## Try:\n","\n","- ### Kernel rbf\n","- ### gamma values  1e-2, 1e-3\n","- ### C values , 1, 10, 100, 1000"]},{"metadata":{"id":"PRIfL-189c62","colab_type":"code","colab":{}},"cell_type":"code","source":["tuned_parameters = [{'kernel': ???\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","                     \n","clf=???\n","                     \n","                     \n","                     \n","                     \n","clf.fit(X, y)\n","\n","\n","print(\"Best parameters set found on development set:\")\n","print(\"\\n\")\n","print(clf.best_params_)\n","\n","means = clf.cv_results_['mean_test_score']\n","stds = clf.cv_results_['std_test_score']\n","for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n","    print(\"%0.3f (+/-%0.03f) for %r\"\n","              % (mean, std * 2, params))\n","                     "],"execution_count":0,"outputs":[]},{"metadata":{"id":"rmOHLvbEzmYl","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(\"Detailed classification report:\")\n","print(\"\\n\")\n","print(\"The model is trained on the full development set.\")\n","print(\"The scores are computed on the full evaluation set.\")\n","print(\"\\n\")\n","y_true, y_pred = y_test, clf.predict(X_test)\n","print(classification_report(y_true, y_pred))\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"uBpyB2ZmBOEw"},"cell_type":"markdown","source":["# <font color=FF103>TO DO: ... now train SVM with the best set of hyperparameters and do the test on X_test </font>"]},{"metadata":{"colab_type":"code","id":"8CsxlWxuBn_A","colab":{}},"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","SVM_model = SVC(???)\n","\n","SVM_model.fit(X,y)\n","\n","y_pred_train = SVM_model.predict(X)\n","y_pred_test = SVM_model.predict(X_test)\n","\n","ACC_SVM_train= np.mean(y == y_pred_train)\n","ACC_SVM_test= np.mean(y_test == y_pred_test)\n","\n","print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n","print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q8eJNOt-N-we","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","SVM_model = SVC(probability=True, kernel = 'rbf', C = 10, gamma= 0.01)\n","\n","SVM_model.fit(X,y)\n","\n","y_pred_train = SVM_model.predict(X)\n","y_pred_test = SVM_model.predict(X_test)\n","\n","ACC_SVM_train= np.mean(y == y_pred_train)\n","ACC_SVM_test= np.mean(y_test == y_pred_test)\n","\n","print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n","print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TCA3ChGR0I-m","colab_type":"text"},"cell_type":"markdown","source":["---\n","# <font color=red>See: </font>[Nested versus non-nested cross-validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)\n","---\n"]},{"metadata":{"id":"5PtgLLKpFMUL","colab_type":"text"},"cell_type":"markdown","source":["# <font color=FF103>TO DO: remember it is very important to go beyond Accuracy   </font>\n","- ## Check what accuraccy we will have if you predict always \"True\" "]},{"metadata":{"id":"EClRay7_4ot8","colab_type":"code","colab":{}},"cell_type":"code","source":["y_false_train = np.zeros(len(y))\n","y_false_test = np.zeros(len(y_test)) \n","\n","ACC_false_train= np.mean(y == y_false_train)\n","ACC_false_test= np.mean(y_test == y_false_test)\n","\n","print(\"Accuracy: Classification Error on TRAIN Data using False %f \" % ACC_false_train)\n","print(\"Accuracy: Classification Error on TEST  Data using False %f \" % ACC_false_test)\n","print(\"\\n\")\n","\n","print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n","print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)\n","print(\"\\n\")\n","\n","print(\"Accuracy: Classification Error on TRAIN Data using LR %f \" % ACC_train)\n","print(\"Accuracy: Classification Error on TEST  Data using LR %f \" % ACC_test)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"8zx8rrHh8eyl"},"cell_type":"markdown","source":["---\n","# <font color=FF103>TO DO: ... beyond Accuracy   </font>\n","- ## Explore the confusion matrix. on y_test  & y_pred_test with SVM  "]},{"metadata":{"id":"n8rVrxLsFMUO","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","confusion_matrix(y_test,y_pred_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v2pXkeye8_Th","colab_type":"text"},"cell_type":"markdown","source":["- ## ... as with Deep Learning we can use the <font color=darkorange>PANDAS</font> confusion matrix"]},{"metadata":{"id":"AGcELZArFMUT","colab_type":"code","colab":{}},"cell_type":"code","source":["! pip install pandas_ml"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vXXdLHMuFMUX","colab_type":"code","colab":{}},"cell_type":"code","source":["from pandas_ml import ConfusionMatrix\n","\n","cm = ConfusionMatrix(y_test,y_pred_test)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GCnwoYcfFMUf","colab_type":"code","colab":{}},"cell_type":"code","source":["cm.print_stats()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Vf9SNXTw9x3F","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"VDqouZ51FMUj","colab_type":"code","colab":{}},"cell_type":"code","source":["cm.plot(backend='seaborn',normalized=True)\n","print(cm)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WrIGdni4FMUm","colab_type":"text"},"cell_type":"markdown","source":["---\n","# <font color=FF103>TO DO: ... beyond Accuracy   </font>\n","- ## Posterior probabilities are needed to analyze DET (or ROC) curves"]},{"metadata":{"id":"GvgNpYtOFMUn","colab_type":"code","colab":{}},"cell_type":"code","source":["# First get posteriors...\n","probs = SVM_model.predict_proba(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DbpzkHHDFMUr","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn import metrics\n","\n","preds = probs[:,1]\n","\n","# calculate the fpr and tpr for all thresholds of the classification\n","fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n","roc_auc = metrics.auc(fpr, tpr)\n","\n","print('AUC : %f' % roc_auc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QbglTaiRFMUy","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.title('Receiver Operating Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"WDUaXIVrJFc0"},"cell_type":"markdown","source":["---\n","# <font color=FF103>TO DO: try improving the prediction of churn True cases  </font>\n","\n","## See SVC docummentation: [sklearn SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n","\n","**class_weight : {dict, ‘balanced’}, optional**\n","\n","     Set the parameter C of class i to class_weight[i]*C for SVC.\n","        example: class_weight={1: 10}\n","    \n","    If not given, all classes are supposed to have weight one.\n","    \n","    The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n","\n","---\n"]},{"metadata":{"colab_type":"code","id":"lrjIAkYMDQCM","colab":{}},"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","SVM_model = SVC(probability=True, kernel = 'rbf', C = 10, gamma= 0.01, class_weight=???)\n","\n","\n","SVM_model.fit(X,y)\n","\n","y_pred_train = SVM_model.predict(X)\n","y_pred_test = SVM_model.predict(X_test)\n","\n","ACC_SVM_train= np.mean(y == y_pred_train)\n","ACC_SVM_test= np.mean(y_test == y_pred_test)\n","\n","print(\"Accuracy: Classification Error on TRAIN Data using SVM %f \" % ACC_SVM_train)\n","print(\"Accuracy: Classification Error on TEST  Data using SVM %f \" % ACC_SVM_test)\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"elOE5GBhO3jj","colab":{}},"cell_type":"code","source":["cm = ConfusionMatrix(y_test,y_pred_test)\n","cm.plot(backend='seaborn',normalized=True)\n","print(cm)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U1hMvzosFMU3","colab_type":"text"},"cell_type":"markdown","source":["## Compare with QDA"]},{"metadata":{"id":"nhUbt_6uFMU6","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CrDTfHrxDk20","colab_type":"text"},"cell_type":"markdown","source":["- ## In this case you can use  *priors*=( ?? ,  ??)\n","\n","### Sklearn documentation: [QuadraticDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)"]},{"metadata":{"id":"XFceBX76FMU-","colab_type":"code","colab":{}},"cell_type":"code","source":["qda_model = QuadraticDiscriminantAnalysis(priors=(0.45,0.55))\n","qda_model.fit(X,y)\n","\n","y_pred_qda = qda_model.predict(X_test)\n","probs_qda = qda_model.predict_proba(X_test)\n","\n","preds_qda = probs_qda[:,1]\n","fpr_qda, tpr_qda, threshold_qda = metrics.roc_curve(y_test, preds_qda)\n","roc_auc_qda = metrics.auc(fpr_qda, tpr_qda)\n","\n","plt.title('Receiver Operating Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC LR = %0.2f' % roc_auc)\n","plt.plot(fpr_qda, tpr_qda, 'g', label = 'AUC QDA = %0.2f' % roc_auc_qda)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LGLjox_gFMVI","colab_type":"code","colab":{}},"cell_type":"code","source":["cm_qda = ConfusionMatrix(y_test, y_pred_qda)\n","cm_qda.plot(backend='seaborn',normalized=True)\n","print(cm_qda)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J-H6XLi8FMVV","colab_type":"code","colab":{}},"cell_type":"code","source":["cm_qda.print_stats()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"8z5p6QUfAb94"},"cell_type":"markdown","source":["---\n","---\n","\n","# <font color=FF103>TO DO: In case you need \"interpretability\"  </font>\n","\n","- ### USE:  max_depth=3"]},{"metadata":{"collapsed":true,"colab_type":"text","id":"oHp5bqUuAb-B"},"cell_type":"markdown","source":["## <font color='green'>Using Classification Tree</font>"]},{"metadata":{"colab_type":"code","id":"AefMLD6OAb-I","colab":{}},"cell_type":"code","source":["from ??? import ???\n","\n","tree_model = ???"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"-4hrdyfaAb-j","colab":{}},"cell_type":"code","source":["print(tree_model)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"wsKt1oboAb-v"},"cell_type":"markdown","source":["- ## To visualize the tree"]},{"metadata":{"colab_type":"code","id":"srWOx0utAb-x","colab":{}},"cell_type":"code","source":["! apt-get update\n","! apt-get autoremove graphviz\n","! apt-get install graphviz"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"l4VuYlw0Ab_A","colab":{}},"cell_type":"code","source":["! pip install graphviz"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"MnnSGZOqAb_O","colab":{}},"cell_type":"code","source":["! pip install pydotplus"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O_pHSdmKFG0V","colab_type":"text"},"cell_type":"markdown","source":["## NOTE: we have used : labels=churn_feat_space.columns.tolist()\n","\n","        To see the label names in the tree"]},{"metadata":{"colab_type":"code","id":"qnkLrvPwAb_f","colab":{}},"cell_type":"code","source":["from sklearn.externals.six import StringIO\n","from graphviz import Source\n","from sklearn.tree import export_graphviz\n","import pydotplus\n","from sklearn import tree\n","from IPython.display import SVG\n","\n","dot_data = StringIO()\n","\n","labels=churn_feat_space.columns.tolist()\n","\n","\n","graph = Source(tree.export_graphviz(tree_model, out_file=None\n","   , feature_names=labels\n","   , class_names=['Churn', 'No_Churn'] \n","   , filled = True))\n","\n","display(SVG(graph.pipe(format='svg')))\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"ihVT41ypAb_4","colab":{}},"cell_type":"code","source":["# NOTE : Scaling\n","\n","churn_feat_space.hist('Total day minutes')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YUmJpySoFUP9","colab_type":"text"},"cell_type":"markdown","source":["- ## Adding the ROC for the tree"]},{"metadata":{"colab_type":"code","id":"CLOLPz5vAcAG","colab":{}},"cell_type":"code","source":["\n","y_pred_tree = tree_model.predict(X)\n","probs_tree = tree_model.predict_proba(X)\n","\n","preds_tree = probs_tree[:,1]\n","fpr_tree, tpr_tree, threshold_tree = metrics.roc_curve(y, preds_tree)\n","roc_auc_tree = metrics.auc(fpr_tree, tpr_tree)\n","\n","plt.title('Receiver Operating Characteristic')\n","plt.plot(fpr, tpr, 'b', label = 'AUC LR = %0.2f' % roc_auc)\n","plt.plot(fpr_qda, tpr_qda, 'g', label = 'AUC QDA = %0.2f' % roc_auc_qda)\n","plt.plot(fpr_tree, tpr_tree, 'm', label = 'AUC TREE = %0.2f' % roc_auc_tree)\n","plt.legend(loc = 'lower right')\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"2hkM2pVKAcAR"},"cell_type":"markdown","source":["---\n","# <font color=FF103>TO DO: ... try Gradient Boosting  </font>"]},{"metadata":{"colab_type":"code","id":"KfRxkYoeAcAV","colab":{}},"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import classification_report\n","\n","# boosting: many many weak classifiers (max_depth=1) refine themselves sequentially\n","# tree is the default the base classifier\n","estimator = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=1, random_state=0)\n","estimator.fit(X, y)\n","y_pred = estimator.predict(X)\n","print(classification_report(y, y_pred))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"h-e8PmjSAcAg"},"cell_type":"markdown","source":["---\n","# <font color=FF103>TO DO: ... try Random Forest  </font>"]},{"metadata":{"colab_type":"code","id":"1Ff03JN4AcAi","colab":{}},"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"2h1d09o-AcAn","colab":{}},"cell_type":"code","source":["RF_model = RandomForestClassifier(max_depth=10,min_samples_split=20).fit(X, y)\n","RF_model.fit(X, y)\n","y_pred_RF = RF_model.predict(X)\n","print(classification_report(y, y_pred_RF))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"XqruE4tCAcAy","colab":{}},"cell_type":"code","source":["RF_model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"67TDgHtdFlrn","colab_type":"text"},"cell_type":"markdown","source":["# <font color=FF103>TO DO: ... review how you can with Random Forest study <font color=green>Feature importances  </font>"]},{"metadata":{"colab_type":"code","id":"HyUGfI1hAcBP","colab":{}},"cell_type":"code","source":["labels=churn_feat_space.columns.tolist()\n","\n","\n","importances = RF_model.feature_importances_\n","std = np.std([tree.feature_importances_ for tree in RF_model.estimators_],\n","             axis=0)\n","indices = np.argsort(importances)[::-1]\n","\n","# Print the feature ranking\n","print(\"Feature ranking:\")\n","\n","for f in range(X.shape[1]):\n","    print(\"%d. feature %s (%f)\" % (f + 1, labels[indices[f]], importances[indices[f]]))\n","\n","# Plot the feature importances of the forest\n","plt.figure(figsize=(14,8))\n","plt.title(\"Feature importances\", fontsize=20)\n","plt.bar(range(X.shape[1]), importances[indices],\n","       color=\"r\", yerr=std[indices], align=\"center\")\n","plt.xticks(range(X.shape[1]), [labels[k] for k in indices],rotation='vertical')\n","ax = plt.gca()\n","ax.tick_params(axis = 'both', which = 'major', labelsize = 16)\n","\n","plt.xlim([-1, X.shape[1]])\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"Ep6oODTIAcBX"},"cell_type":"markdown","source":["---\n","# <font color=FF103>TO DO: ... try GridSearch for Random Forest  </font>"]},{"metadata":{"colab_type":"code","id":"rlkFK61_AcBa","colab":{}},"cell_type":"code","source":["# Utility function to report best scores\n","def report(results, n_top=3):\n","    for i in range(1, n_top + 1):\n","        candidates = np.flatnonzero(results['rank_test_score'] == i)\n","        for candidate in candidates:\n","            print(\"Model with rank: {0}\".format(i))\n","            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n","                  results['mean_test_score'][candidate],\n","                  results['std_test_score'][candidate]))\n","            print(\"Parameters: {0}\".format(results['params'][candidate]))\n","            print(\"\")"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"XMcjL9k6AcBk","colab":{}},"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","from time import time\n","\n","RF_grid = RandomForestClassifier(n_estimators=20)\n","\n","# use a full grid over all parameters\n","param_grid = {\"max_depth\": [3, None],\n","              \"max_features\": [1, 3, 10],\n","              \"min_samples_split\": [2, 3, 10],\n","              \"bootstrap\": [True, False],\n","              \"criterion\": [\"gini\", \"entropy\"]}\n","\n","# run grid search\n","grid_search = GridSearchCV(RF_grid, param_grid=param_grid, cv=5)\n","start = time()\n","grid_search.fit(X, y)\n","\n","print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n","      % (time() - start, len(grid_search.cv_results_['params'])))\n","report(grid_search.cv_results_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"25B7Z1tUFMVa","colab_type":"text"},"cell_type":"markdown","source":["# <font color=brown>You can also use: Model selection with Cross validation</font> using scikit-learn libraries.\n","https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n","\n","https://scikit-learn.org/stable/modules/cross_validation.html#k-fold\n","\n"]},{"metadata":{"id":"BNdcgWrdFMVb","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn import model_selection\n","\n","# prepare configuration for cross validation test harness\n","seed = 7\n","# prepare models\n","models = []\n","models.append(('LR', LogisticRegression()))\n","models.append(('LDA', LinearDiscriminantAnalysis()))\n","models.append(('QDA', QuadraticDiscriminantAnalysis()))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uo3Xtt6gFMVf","colab_type":"code","colab":{}},"cell_type":"code","source":["# evaluate each model in turn\n","results = []\n","names = []\n","scoring = 'accuracy'\n","for name, model in models:\n","    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n","    results.append(cv_results)\n","    names.append(name)\n","    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n","    print(msg)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xros-2E-FMVm","colab_type":"code","colab":{}},"cell_type":"code","source":["# boxplot algorithm comparison\n","fig = plt.figure()\n","fig.suptitle('Algorithm Comparison')\n","ax = fig.add_subplot(111)\n","plt.boxplot(results)\n","ax.set_xticklabels(names)\n","plt.show()"],"execution_count":0,"outputs":[]}]}